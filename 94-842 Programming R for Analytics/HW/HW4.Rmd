  ---
title: "Assignment 4"
author: "Michelle Hsu"
output: 
  html_document:
    toc: true
    theme: paper
    highlight: tango
---

Some of this problem is modified from Dr. Chouldechova's notes for Lecture 7, http://www.andrew.cmu.edu/user/achoulde/94842/index.html. I like the way she uses simulation to cover hypothesis testing, and you are free, even encouraged, to use her lecture notes in completing this problem.  However, I place some constraints on how your code to ensure your solution is different than what is on Dr. Chouldechova's notes. 

### Problem 1 (2.5 pts)
Write a function called "sample.maker" that generates a random sample of normally distributed outcomes for two different groups: a control group and a treatment group. "sample.makder" should take five arguments: means for each group, sample sizes for each group, and a standard deviation assumed to be equal for both groups. "sample.maker" should return a dataframe with two columns, group and outcome, where the outcome is randomly generated per the distribution statistic arguments (meand and std dev). The number of rows should be the total sample size (treatment plus control group). Test your function by generating a sample with treatment and control sample sizes of 100 and 80; treatment and control sample means of 30 and 29, and a standard deviation of 5. Show that your function worked by printing a boxplot of its result. **Your code must simulate samples for each group using separate lines of code.** 

```{r}
require(ggplot2)
require(tidyverse)
require(MASS)
```

```{r}
sample.maker <- function(nt,nc,mt,mc,s){
    samples<- rnorm(nt, mean = mt, sd = s) #generate nt random sample with mean = mt and standard deviation =s
    sim.with.tsample <- cbind(samples, rep("treatment", nt)) # bind the simulation value to the treatment.sample
    samples<- rnorm(nc, mean = mc, sd = s) #generate nc random sample with mean = mc and standard deviation =s
    sim.with.csample <- cbind(samples, rep("control", nc)) # bind the simulation value to the control.sample 
    random.samples <- rbind(sim.with.tsample, sim.with.csample) # bind the treatment sample to control sample
    random.samples <- as.data.frame(random.samples)
    colnames(random.samples) <- c("samples", "group")
    random.samples$group <- as.factor(random.samples$group)
    random.samples$samples <- as.numeric(random.samples$samples)
  return(random.samples)
}
s <- sample.maker(100,80,30,29,5)

ggplot(s,aes(x = group, y = samples, fill = group))+
  geom_boxplot()

```


### Problem 2 (0.5 pt)
The formula for the t-test for a difference in group means is 

t.two.sample = ((mean1 - mean2) - (hypothesized difference)) / sqrt(var1^2/n1 + var2^2/n2) 
      
This is often called a "two-sample" t-test because we draw on two samples: a control and a treatment group. For an overwhelming majority of applications, we are interested only in differences in group means, e.g., the hypothesized difference is equal to zero. We also often assume equal group variances (var1 = var2). In the special case where the group sample sizes are also equal, the two-sample t-test often simplifies to

t.two.sample.means.equal.var = (mean1 - mean2) / sqrt(2*var^2/n) 
                             = (mean1 - mean2) / (stdev * sqrt(2/n)

In class, we conducted a one sample t-test with KNOWN population mean and standard deviation using the following test statistic.

z.one.sample = (sample mean - population.mean) / (population.stdev / sqrt(n))

What is the "signal" and what is the "noise" for the one sample test (z.one.sample) and the two sample test (t.two.sample.means.equal.var)? For which test is the noise larger? Why do you think that is?

```{r}
#In one sample test, the signal is the difference between sample mean and population mean(sample mean - population.mean), and the noise is the standard error(stdev / sqrt(n)); while in two sample test, the signal is the diparity of difference in two sample means(mean1 - mean2) and the hypothesized difference, and the noise is the combined standard errors(sqrt(var1^2/n1 + var2^2/n2)) of the two samples. The noise for two sample test should be larger because we conduct the the test based on two samples, which introduces more nosie to the test. Also, based on the formula, the noise for one sample test is (stdev / sqrt(n)) and the ones for two sample test is (stdev * sqrt(2/n)), assumed the variances of two samples are equal. The noise for two sample test is obviously bigger than one sample test.
```

*Note answers to this question should be only text. No math or calculations.*

### Problem 3 (3.5 pts)
Now write a function called "p.val.generator" that repeatedly prepares a sample using your function from Problem 1. For each sample, "p.val.generator" should conduct a t-test for the difference in means across the control and treatment groups and return the p-value from the t-test. In addition to all the arguments required of "sample.maker," the number of desired simulations should also be an arguments to "p.val.generator." "p.val.generator" should return a dataframe with two columns: the incremental simulation number (e.g., 1, 2, 3, etc.) and the p-value from that simulations. Test your function by repeating t-tests for 1000 samples assuming there is no difference in outcome between a treatment and control groups with equal sample sizes of 100, sample means of 30, and a standard deviation of 10. Show a histogram of the resulting p-values.  Assuming a critical value of 0.05, what type of error (I or II) is occurring when the t test returns a p-value below 0.05? Are these errors present in the tests from your simulated samples? 

```{r}
p.val.generator <- function(n,nt,nc,mt,mc,s){
  test <- data.frame(index = as.numeric(), p.value = as.numeric())
  for (i in 1:n) {
      index <- i
      temp <- sample.maker(nt,nc,mt,mc,s)
      t.test.samples <- t.test(temp$samples ~ temp$group)
      p<- t.test.samples$p.value
      t <- cbind(index, p)
      test <- rbind(test,t)
  }
  colnames(test) <- c("index", "p.value")
  return(test)
}

result <- p.val.generator(1000,100,100,30,30,10) 

 ggplot(result, aes(x = p.value)) +
  geom_histogram(alpha=0.75, position="identity") +
  geom_vline(xintercept =0.05, colour="red") +
  xlim(0,1)

#If the p-value is below 0.05(critical value), a type I error might occur because you might reject a correct null hypothesis.
#Both type of errors can be presented in the test from simulated samples. If the test on your simulated samples produce a p-value lower than the critical value, you reject the null hypothesis, which implies that you might conduct a type I error. On the other hand, if the p-value is higher than the critical value, you fail to reject the null hypothesis, which implies that you might conduct a type II error. In other words, you fail to reject a false null hypothesis.Although in this case, it is more likely to conduct a type II error than type I error since the most of the p-values is larger than 0.05.
```



### Problem 4 (1.5 pts)

##### Part a. 
Using "p.val.generator," run 1000 sumulations assuming the sample distribution values from Problem 1 (treatment and control sample sizes of 100 and 80; treatment and control sample means of 30 and 29, and a standard deviation of 5). Plot a histogram of the resulting p-values and use this a reference for parts b and c. 
```{r}
x <- p.val.generator(1000,100,80,30,29,5)

plot.sample <- ggplot(x, aes(x = p.value)) +
  geom_histogram(alpha=0.75, position="identity") +
  xlim(0,1)

plot.sample
```

##### Part b.
Using the distribution and inputs from part a as a reference, identify one arguement that will increase the likelihood that you reject the null hypothesis of zero difference in group means. Relative to part a, change the value of this argument so that most tests - but not all - would reject the null hypothesis at a crtical p-value of 0.05. Show the distribution of p values from your tests. In ONE SENTENCE, explain why the distribution of p-values are different. 
```{r}
#If I change the standard deviation from 5 to 3, it will increase the likelihood of rejecting the null hypothesis because the z value(test statistic) will increase, which means the p-value will decrease.The distribution of p-values is different because the noise(standard deviation) in the hypothesis test is changed.

z <- p.val.generator(1000,100,80,30,29,3)

plot.sample1 <- ggplot(z, aes(x = p.value)) +
  geom_histogram(alpha=0.75, position="identity") +
  xlim(0,1)

plot.sample1

```

##### Part c. 
Again using part a as a reference, repeat all of part b choosing a different parameter (if you use a group mean for part b, do not use the other group mean for part c). In ONE SENTENCE, again explain why the distribution of p-values are different.

```{r}

#The reason why the distribution of p-values is different is because the signal(difference in means between control group and treatment group) in the hypothesis test is bigger.

w <- p.val.generator(1000,100,80,30,27,5)

plot.sample2 <- ggplot(w, aes(x = p.value)) +
  geom_histogram(alpha=0.75, position="identity") +
  xlim(0,1)

plot.sample2
```

